\chapter{PEM Algorithms}~\label{PEM}

In this part, we will present a review of different and classical algorithms in the PEM model of computation. We will start by presenting the general purpose algorithms, those that serve as building blocks for many other problems. We will follow by those who are related to graphs and their inherent complexity, then will come those related to more geometric problems. We will then present the algorithms linked to the matrices and finally we will come back to sorting ones due to their capital importance.

We would like to emphasize that the PEM computation model focuses on the number of blocks transferred between a supposedly large and slow external memory and a small and fast internal one since the idea is that making a memory request is longer than making a computation. The parallel aspect is translated by several processors, each having their own internal memory and being able to communicate between them through the external memory. Each cache is of size $M$, is partitioned in blocks of size $B$ and is exclusive to each processor, i.e., processors cannot access other processors' caches. To
perform any operation on the data, a processor must have the data in its own cache and the data is transferred between the main memory and the cache in blocks of size $B$.

The parameters are as follows:
\begin{itemize}[label={}]
    \item $N$ is the problem size.
    \item $M$ is the internal memory\index{Cache} size.
    \item $B$ is the block\index{Block} transfer size.
    \item $P$ is the number of processors.
\end{itemize}

\begin{figure}[!htb]
    \centering
    \includegraphics[width=0.4\linewidth]{Chapters/GPU/PEM.png} 
    \caption{PEM model}
\end{figure}

The model complexity measures the number of parallel block transfers between the main memory and the cache by the processors. For instance, an algorithm reading one block (or different) with each of the $P$ processors simultaneously from the main memory would have an I/O complexity of $O(1)$ and not $O(P)$.

Many of the following algorithms will have the assumption that $M \geq B^{O(1)}$ (or its weaker version $M = \Omega(B^{1 + \epsilon})$). This is called the tall-cache assumption, G.S. Brodal and R. Fagerberg prove that without the tall-cache assumption, sorting cannot be performed optimally and permuting elements is not cache-oblivious even under this property~\cite{brodal2003limits}.

\input{Chapters/GPU/Algorithms/Algorithm}

\input{Chapters/GPU/Algorithms/Graph}

\input{Chapters/GPU/Algorithms/Geometrical}

\input{Chapters/GPU/Algorithms/Matrix}

\input{Chapters/GPU/Algorithms/Sort}