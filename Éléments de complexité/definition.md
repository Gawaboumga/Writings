Mais qu'est-ce donc que la complexité ? Il est coutumier de commencer toute présentation d'un concept par une définition issue du dictionnaire. Donc, faisons différemment et préférons l'approche didactique en mettant en relief les caractères distinctifs du concept !

La complexité en elle-même n'a que peu de sens, c'est une caractérisation de ce qui est qualifié de "complexe" par le sens commun. "Aller sur Mars" est très complexe mais "faire de la couture" l'est nettement moins. Et pourtant, rares sont ceux capables de coudre. Ce concept nécessite souvent une base de comparaison par rapport à un objet de même nature qui l'est davantage ou moins. Il est peu rigoureux d'annoncer quelque chose comme difficile ou simple sans fournir des justificatifs par rapport à des problèmes précédemment rencontrés ou communément acceptés. Il y a un doux mélange de raisons objectives et subjectives pour lesquelles on estime une tâche plus dure qu'une autre, que ce soit par les ressources que cela demande dans l'absolu (aller sur Mars) et la perception que l'on possède du problème (si je suis déjà couturier professionnel).

La complexité cherche donc à déterminer comment on peut définir à quel point une tâche est complexe.

En Sciences, on essaye d'éviter au maximum l'aspect subjectif et on tente de trouver une approche sur laquelle tout le monde peut se baser, la plus objective possible et éventuellement quantifiable. Prenons, le cas d'un jeu de cartes, chercher l'as de trèfle dans le paquet est intuitivement plus simple que de trier le paquet par valeur et par symbole, malgré que le nombre de cartes est le même dans les deux situations. Ce qui soutient cette idée, c'est qu'il suffit de parcourir toutes les cartes jusqu'à tomber éventuellement sur l'as de trèfle alors que, pour trier, on va sans doute parcourir plusieurs fois le paquet et échanger la position de nombreuses cartes.

En cherchant à rationnaliser le problème, on se rend compte que le nombre de *ressources* demandées pour effectuer ces tâches sont différentes, que ce soit dans le nombre de cartes qu'il faut regarder pour pouvoir répondre à ces questions, le nombre de manipulations entre les mains ou encore le nombre de cartes qu'il faut échanger de places. Et on peut se demander à quel point ces observations auraient été similaires avec seulement 2 cartes ou bien 3 paquets.

La complexité peut donc varier tant en fonction de la taille du problème que selon critère qu'on étudie, et ce pour une même tâche.

Seulement, les résultats qu'on pourrait obtenir avec le jeu de cartes pourraient difficilement être transposés à d'autre problèmes, telle que la résolution d'un système d'équations. Le problème de fond est qu'il est difficile que ce soit d'exprimer ou de comparer la complexité de ces tâches spécifiques par rapport à des problèmes plus génériques. Il faudrait pouvoir définir un modèle, un ensemble de règles, tel qu'on puisse exprimer tous ces problèmes dans un même langage, qui permettrait alors plus facilement de les analyser et de les comparer. L'avancée majeure dans le domaine a été les résultats liés à la "Thèse de Church-Turing" [^CHURCH, Alonzo. An unsolvable problem of elementary number theory. American journal of mathematics, 1936, vol. 58, no 2, p. 345-363.] [^TURING, Alan M. Computability and λ-definability. The Journal of Symbolic Logic, 1937, vol. 2, no 4, p. 153-163.] et du problème de la décision (*Entscheidungsproblem*) au milieu des années 30 et qui s'est étendu pendant une dizaine d'année. Les très nombreux résultats issus de ces travaux dépassent très largement le contenu de cet article mais celui qui nous intéresse est le suivant:

"Il est possible d'exprimer, par un ensemble de *règles de calcul*, tout ce qui est calculable en suivant un traitement systématique, un algorithme.". Réciproquement, on définit ce qui est calculable comme étant tout ce qui peut s'exprimer aux travers de ces règles de calcul, en les appliquant selon un ordre précis, un algorithme.

C'est le problème de ce genre de résultats, ils apportent davantage de questions qu'ils n'en résolvent … Autrement dit, il existe des problèmes qui sont dits "calculables", où il est possible de répondre à la question qui est posée en un nombre *fini* de ressources (et donc qu'il existe des problèmes qu'on ne peut résoudre et dits *incalculables*, peu importe le temps qu'on y consacre) - et la question de la calculabilité mériterait son propre article en lui-même. Et ces problèmes "calculables" peuvent tous être exprimés dans un langage - ensemble (fini) de règles de calcul - commun et ce par un système qui peut être automatisé, il suffit d'"appliquer les règles". Ces règles se voulant le plus simple possible, elles peuvent se traduire par des actions telles que "ajouter 1 au nombre actuel".

Il y a donc une relation très forte entre ce qu'on définit comme étant calculable et l'ensemble des règles de calcul que l'on choisit. La réciproque n'étant pas forcément uniquement, l'ensemble des problèmes, que l'on peut résoudre, peut correspondre à plusieurs ensembles de règles de calcul différents. Le résultat de la Thèse de Church-Turing était extrêmement fort parce qu'il montrait qu'on était capable d'exprimer une bonne partie des problèmes mathématiques sous la forme de questions que l'on était capable de résoudre et ce, avec des règles relativement simples.

Pour résumer, la complexité s'intéresse à la définition et la quantification de la difficulté des tâches. Ces dernières sont exprimées par un ensemble de règles de calcul, opérations élémentaires; plus il faut appliquer de règles, plus la tâche est complexe. La taille du problème a donc une relation très forte avec la complexité puisqu'il faudra sans doute appliquer davantage de règles pour arriver au même résultat. Également en fonction de ou des règles que l'on considère, la complexité peut également varier et ce pour un même problème.